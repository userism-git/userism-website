<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Big Tech or Digital Democracy?</title>
    <style>
        body { font-family: sans-serif; line-height: 1.6; max-width: 800px; margin: auto; padding: 20px; }
        img { width: 100%; height: auto; border-radius: 8px; }
        .byline { color: #666; font-style: italic; margin-bottom: 20px; }
    </style>
</head>
<body class="articles">
    <article>
        <img src="assets/images/article1.jpg" alt="Logo of the Userist Collective">
<h1>Big Tech or Digital Democracy?</h1>
                <p class="byline">Renato Pisani • November 2o, 2025</p>
<p>
    On 21 January 2025, U.S. President Donald Trump hosted the CEOs of OpenAI, Oracle, and SoftBank at the White House to unveil a colossal project: Stargate. A 500-billion-dollar plan to build massive computing hubs across the country. Each hub will house hundreds of thousands of microprocessors and will be used to train the most advanced AI models. In particular, Stargate will fuel the growth of generative AI, the kind capable of producing text or images, such as ChatGPT. The project has raised concerns about its environmental and labour impact. Stargate will consume as much energy as that used by hundreds of thousands—if not millions—of Italians, and will also require large amounts of water for cooling. Yet despite the resources involved and the money invested, according to OpenAI the jobs created will number only a few tens of thousands.
    The aim of this article, however, is not to debate these issues, but to identify in Stargate—and in similar projects funded by other companies—a shift in the structure of digital capital and in the balance of power across society. At the heart of this shift is the role of the major tech companies, which are steering the world, willingly or not, through a turbulent phase of transformation. This change begins with their own profit model. For Big Tech, a fundamental paradigm has shifted: where they once focused on accumulating and selling data, they now treat data as raw material for a new, even more profitable production process—the development of generative AI systems. As a result, they have begun investing vast sums not only to centralise user data in data centres, but also to centralise computing power itself, which until now was distributed across users’ devices. It is a transformation within the digital sphere analogous in impact to the industrial revolution that upended large agrarian estates. 
    Today’s generative AI is possible only thanks to the immense quantities of data accumulated during the old Internet era. But to improve and scale, it requires computing power capable of processing that data as fast as possible. The result is a further concentration of economic and political influence in the hands of the companies driving this revolution.
</p>

        <h3>The Future of Digital Profit</h3>

<p>
    These companies are the usual suspects—Google, Amazon, Microsoft, Meta—plus one new name: OpenAI, the start-up behind ChatGPT. All are pouring billions into AI infrastructure and development, through projects that range from independent to deeply interconnected. Yet none of them is currently generating real financial returns. OpenAI expects its first net profit in 2029.
There is ongoing debate about whether the sky-high valuations of the AI market are largely speculative. The young OpenAI is valued at around 500 billion dollars, while Nvidia—the near-monopolist in AI chips—exceeds 5 trillion. A bubble is likely: valuations may crash, and some peripheral firms may fail. But from the perspective of Big Tech, long-term profit prospects justify every dollar spent. <br>Expected returns span strategic applications such as warfare, public administration, and healthcare. But most profits will probably continue to come from vast masses of individual digital consumers. Big Tech is betting that users will be increasingly drawn to technology that is extremely convenient and personalised, compared to the static systems of the “old digital”.
AI promises dynamic, personalised digital environments, where speaking is enough to obtain almost anything—an enormous leap beyond search engines like Google or operating systems like Windows. LLMs like ChatGPT or Gemini sit at the core of this offer, integrating with audio systems, graphics, and third-party apps to deliver a seamless experience. In return, through conversations with LLMs, users provide companies with extremely granular personal data. This will improve the quality of data collection in Big Tech’s hands, allowing them to refine personalised, almost intimate communication strategies to push profitable content such as advertising. Their ability to influence users will strengthen—this is the real power held by digital capital.
</p>

       <h3>Generative AI and the Degeneration of the User</h3>

<p>Influence underpins the strength of digital capital. Today, most Big Tech firms use this power to generate advertising revenue. Their primary tools remain social-media and search-engine algorithms which, through machine learning, adopt autonomous strategies tailored to each individual. These strategies vary in content but reduce to three basic tactics:
<strong>1) personalisation, to maximise time spent online; 2) emotional stimulation, to weaken psychological defences; 3) atomisation, the fragmentation of users into small, isolated bubbles </strong> to strengthen grip over individuals or groups, while making collective reactions harder.
These patterns are not necessarily designed in advance but are behaviours AI has discovered to perform its tasks effectively, benefiting the companies.
Generative AI and modern neural networks can amplify all three tactics, for example by producing content rather than merely reshuffling it. First, personalisation evolves into something fully personal. An LLM like ChatGPT is programmed to imitate its user, mirroring tone, fulfilling desires, and autonomously adopting engagement strategies. Second, emotional influence deepens, because the human–machine interaction demands less intellectual effort from the user. AI can guide the user’s experience across all forms of consumption, responding almost solely to emotional cues. Third, atomisation hardens, creating countless micro-bubbles that span the entire digital experience rather than individual apps. A pervasive AI system, functioning like an operating system, can mediate all interactions and all incoming content.
It is natural for Big Tech to use these systems to expand their influence. But this trajectory risks producing a “degeneration of the user,” reducing individuals to an idealised model optimised for profit, rather than citizens suited to democratic society. If the user is not free and independent in the digital sphere, the corresponding citizen is unlikely to be fully free in the physical one. AI therefore places society at a crossroads: either toward a distributed digital infrastructure with empowered users, or toward the dominance of private profit, threatening rights beginning with labour and well-being.
</p>
        <h3>Digital Democracy and Italian Politics</h3>
<p>
    Italy, as a political and institutional system, has limited hope of reversing user degeneration or halting the concentration of digital capital, mainly for two reasons: dependence on the United States and the inertia of Italian politics.
On the first point, Italy and Europe depend on the U.S. for a vast range of technologies, from operating systems to cloud services, social platforms, and AI. This dependence is a major obstacle to democratic oversight of the digital sphere. The threat of political or economic retaliation prevents democratic governments from taking radical decisions, leaving them subject—willingly or not—to opaque choices made overseas. They manage to pass only moderate measures, such as the GDPR and the AI Act, Europe’s landmark digital regulations adopted in 2016 and 2024. Though highly significant, and far more radical than the unrestrained U.S. market, they are insufficient to reverse user degeneration because they do not address infrastructure or profit structures. U.S. Big Tech remains in control of the digital sphere, acting in close coordination with the U.S. government and the Pentagon, with which it shares a long-standing, lucrative, and strengthening relationship. European regulation, however detailed, is therefore not enough. Its proposals risk being sidestepped, ignored, or weakened by future pressure, leaving European citizens with incomplete and fragile protection.
Turning to Italian politics, an examination of the electoral programmes for the 2024 European Parliament elections reveals a lack of major ideas. Overall, the Five-Star Movement offers the most wide-ranging vision, linking digital issues to many dimensions of human life, though its proposals remain focused on specific risks such as cyberbullying or the environment. The Democratic Party shows the greatest concern for democratic control, offering significant proposals such as entrusting data centres to non-profits to ensure transparent, Big-Tech-free data storage. Still, no programme outlines a vision that connects all elements of digital and AI transformation. No party appears concerned about user degeneration or the centralisation of computing power—crucial factors in reshaping the trajectory of private digital development.
</p>
<h3>Four Principles for Digital Democracy</h3>
<p>
In the absence of political will, initiative falls to citizens. A vision of digital democracy is needed—one capable of sparking public interest and laying the groundwork for user emancipation. Below are several principles that could help frame a radical yet concrete discussion.
<br><strong>1) First, users must not be exploited.</strong> Digital activities should be based on the assumption that data is not collected for profit, unless through systems ensuring direct economic redistribution to citizens. Transparency and open-source approaches should be mandatory for any platform adopting data-for-profit model.
<br><strong>2) Second, users must not be manipulated.</strong> Hyper-personalisation in social media and AI should be phased out. AI-generated content should always self-identify as such, cite its sources, and avoid personal or friendly tones that trigger emotional responses. Social-media feeds should be less strategic and anchored to transparent criteria to reduce addiction and atomisation.
<br><strong>3) Third, digital infrastructure must be distributed.</strong> Computing power should be shared among public institutions, private companies, individuals, and civil society, preventing Stargate-style centralisation. Local communities should have the authority to decide whether and when to build computing hubs or data centres, with substantial control and direct economic benefit.
<br><strong>4) Fourth, the people must retain control.</strong> A digital supply chain should be built to be as autonomous and barrier-free as possible, ensuring democratic control flows through local institutions rather than foreign governments or private corporations. National and supranational democratic governments should commit fully to making this right a reality.
</p>
       <p>
           <i>
           Human assisted AI translation. This article was originally published in Italian. You can find it <a href="https://volerelaluna.it/societa/2025/11/20/big-tech-o-democrazia-digitale/" class="active">here</a>.
         </i>
       </p>
    </article>
    
<div style="margin-top: 40px; display: flex; gap: 10px; flex-wrap: wrap;">
    <!-- Back Button -->
    <a href="../articles.html" style="
        display: inline-block;
        background-color: #00FFFF; 
        color: #000000; 
        padding: 12px 24px; 
        text-decoration: none; 
        font-weight: bold; 
        border-radius: 5px;
        font-family: sans-serif;
    ">← Back to Articles</a>

    <!-- Share Button -->
    <button onclick="shareArticle()" style="
        display: inline-block;
        background-color: #FFFF00; 
        color: #000000; 
        padding: 12px 24px; 
        cursor: pointer;
        font-weight: bold; 
        border-radius: 5px;
        font-family: sans-serif;
    ">Share ↗</button>
</div>

<script>
function shareArticle() {
    if (navigator.share) {
        navigator.share({
            title: document.title,
            text: 'Check out this article: ' + document.title,
            url: window.location.href
        }).catch(console.error);
    } else {
        // Fallback for browsers that don't support native share
        alert("Sharing is not supported on this browser. You can copy the URL to share!");
    }
}
</script>
    
    <script src="index.js"></script>
</body>
</html>
